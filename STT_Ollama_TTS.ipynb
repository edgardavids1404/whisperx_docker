{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukLY81v1fo74"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Step 1: Download the video and turn it into wav file\n",
        "\"\"\"\n",
        "!apt update\n",
        "!apt install -y ffmpeg\n",
        "!python -m pip install -U pytubefix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytubefix import YouTube\n",
        "from pytubefix.cli import on_progress\n",
        "\n",
        "url = \"https://youtu.be/lnln7QkR30w\"\n",
        "folder = \"yt\"\n",
        "filename = \"sample.mp4\"\n",
        "\n",
        "yt = YouTube(url, on_progress_callback = on_progress)\n",
        "print(yt.title)\n",
        "\n",
        "ys = yt.streams.get_highest_resolution()\n",
        "ys.download(folder, filename)"
      ],
      "metadata": {
        "id": "bY_lpRpQgKf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i yt/sample.mp4 -acodec pcm_s16le -ar 16000 -ac 1 -y sample.wav"
      ],
      "metadata": {
        "id": "NqO7SXUmgKrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Install whisperx + cudnn (needed for colab's 12.4 CUDA)\n",
        "\"\"\"\n",
        "!pip install whisperx\n",
        "!apt install libcudnn8 libcudnn8-dev -y"
      ],
      "metadata": {
        "id": "ZnmKout5gRyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Step 2: Transcribe the audio file using WhisperX\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import whisperx\n",
        "import gc\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# os.environ[\"HF_TOKEN\"] = ''\n",
        "\n",
        "# --- Configuration ---\n",
        "device = \"cuda\"\n",
        "audio_file = \"sample.wav\"\n",
        "batch_size = 4\n",
        "compute_type = \"float16\"  # or \"int8\" for lower memory usage\n",
        "\n",
        "# --- WhisperX Transcription ---\n",
        "print(f\"Loading WhisperX model for '{compute_type}' computation on '{device}'...\")\n",
        "try:\n",
        "    model = whisperx.load_model(\"large-v3\", device, compute_type=compute_type)\n",
        "    print(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading WhisperX model: {e}\")\n",
        "    print(\"Please ensure you have the necessary dependencies and a compatible device (CUDA if 'device' is 'cuda').\")\n",
        "    exit()\n",
        "\n",
        "print(f\"Loading audio from '{audio_file}'...\")\n",
        "try:\n",
        "    audio = whisperx.load_audio(audio_file)\n",
        "    print(\"Audio loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading audio file: {e}\")\n",
        "    print(\"Please check if the audio file exists and is a valid .wav format.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Starting transcription...\")\n",
        "try:\n",
        "    result = model.transcribe(audio, batch_size=batch_size)\n",
        "    print(\"Transcription complete.\")\n",
        "\n",
        "    # The 'result[\"segments\"]' contains the transcribed text with timestamps.\n",
        "    # To get the full text, we'll concatenate the 'text' from each segment.\n",
        "    full_transcription = \" \".join([segment[\"text\"] for segment in result[\"segments\"]])\n",
        "    print(\"\\n--- Full Transcription ---\")\n",
        "    print(full_transcription)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during transcription: {e}\")\n",
        "    print(\"This might be due to insufficient GPU memory, an issue with the audio file, or other system-level problems.\")\n",
        "    exit()\n",
        "\n",
        "# free up memory\n",
        "del model\n",
        "# del model_a # if you used align model\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "xM6aiZzngUhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Step 3: Clean the transcribed text using Ollama\n",
        "\"\"\"\n",
        "import requests\n",
        "\n",
        "# Configuration\n",
        "OLLAMA_ENDPOINT = \"http://192.168.20.51:11434/api/generate\"  # Update with your server URL\n",
        "MODEL_NAME = \"gemma3:27b\"  # e.g., \"mistral\", \"llama2\", or your custom model\n",
        "\n",
        "# Sample ASR-generated text (replace with your actual input)\n",
        "asr_text = str(full_transcription)\n",
        "\n",
        "# Construct the prompt with clear instructions\n",
        "prompt = f\"\"\"\n",
        "### Instruction:\n",
        "Clean and correct the following ASR-generated text:\n",
        "1. Add appropriate punctuation (periods, commas, question marks).\n",
        "2. Fix any obvious speech recognition errors.\n",
        "3. Preserve the original language it was spoken in (mostly persian and english).\n",
        "4. Preserve all original content meaning.\n",
        "\n",
        "### Input Text:\n",
        "{asr_text}\n",
        "\n",
        "### Cleaned Text:\n",
        "\"\"\"\n",
        "\n",
        "print(prompt)\n",
        "\n",
        "prompt = prompt.replace('\\n', '\\\\n')\n",
        "\n",
        "with open(\"prompt.txt\", \"w\") as file:\n",
        "  file.write(prompt)\n",
        "\n",
        "# Prepare the request payload\n",
        "payload = {\n",
        "    \"model\": MODEL_NAME,\n",
        "    \"prompt\": prompt,\n",
        "    \"stream\": False,  # Set to True if you want streaming response\n",
        "    \"options\": {\n",
        "        \"temperature\": 0.0,  # Low temperature for minimal creativity\n",
        "        \"num_ctx\": 4096      # Context window size\n",
        "    }\n",
        "}\n",
        "\n",
        "# Send request to Ollama\n",
        "try:\n",
        "    response = requests.post(\n",
        "        OLLAMA_ENDPOINT,\n",
        "        json=payload,\n",
        "        headers={\"Content-Type\": \"application/json\"},\n",
        "        timeout=300  # Increase timeout for longer texts\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "\n",
        "    # Extract cleaned text from response\n",
        "    result = response.json()\n",
        "    cleaned_text = result.get(\"response\", \"\").strip()\n",
        "\n",
        "    print(\"Cleaned Text Output:\")\n",
        "    print(cleaned_text)\n",
        "\n",
        "    with open(\"cleaned_text.txt\", \"w\") as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Request failed: {e}\")"
      ],
      "metadata": {
        "id": "wEk5iSxGloHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Step 4: Convert the cleaned text to speech using Piper\n",
        "\"\"\"\n",
        "!pip install piper-tts"
      ],
      "metadata": {
        "id": "EiMRfUM8m0WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat cleaned_text.txt | piper \\\n",
        "  --update-voices \\\n",
        "  --model fa_IR-reza_ibrahim-medium \\\n",
        "  --output_file reza_ibrahim.wav"
      ],
      "metadata": {
        "id": "llnwZxwknPrI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
